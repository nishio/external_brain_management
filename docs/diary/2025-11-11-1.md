# 2025-11-11 作業記録

## 実施内容

### 1. memプロジェクトの調査

- memリポジトリのREADMEにあった「GPT3.5 ChatGPT APIを使った新しい翻訳システムを開発中」という記述を調査
- external_brain_in_markdownの履歴を検索
- 結果：2023-12-09に書かれた計画だったが、わずか4日後（2023-12-13）に放棄されていた
  - 理由：「Quartzは無限のカスタマイズ性があり、フォーカスがぼやける」
- 現状（2025年）：DeepL翻訳ベースのまま、GPT3.5への移行は未完了

### 2. 新しいマークダウンビューアの実装

#### 目標
- `https://mem.nhiro.org/ja/<page>` で日本語マークダウン表示
- `https://mem.nhiro.org/en/<page>` で英語マークダウン表示
- Scrapbox APIではなく、ローカルのマークダウンファイルから直接レンダリング

#### 実装内容

**データソース**：
- 日本語：`external_brain_in_markdown` リポジトリ
- 英語：`external_brain_in_markdown_english` リポジトリ

**技術スタック**：
- Next.js 12のISR (Incremental Static Regeneration)
- revalidate: 30秒
- gray-matter：フロントマター解析
- marked：マークダウン→HTML変換

**主な機能**：
- Wiki-styleリンク変換：`[[link]]` → `/lang/link`
- 言語切り替え機能（ja/en）
- ページが存在しない場合の適切なフォールバック

### 3. アーキテクチャ問題の解決

#### 初期の間違い
- memリポジトリ内にサブモジュールを追加してしまい、ネストしたサブモジュール構造になった
- 結果：同じリポジトリが2箇所にcloneされる無駄が発生

#### 正しい構造への修正
ユーザーからの指摘：「いや、違うよ。親でexternal_brain_in_markdown_englishをsubmoduleにして、memはln -sすべき」

**修正後の構造**：
```
external_brain_management/         # 親リポジトリ
├── modules/
│   ├── external_brain_in_markdown/           # サブモジュール
│   ├── external_brain_in_markdown_english/   # サブモジュール（新規追加）
│   └── mem/
│       └── data/
│           ├── ja -> ../../external_brain_in_markdown  # シンボリックリンク
│           └── en -> ../../external_brain_in_markdown_english  # シンボリックリンク
```

### 4. Next.jsルーティング問題の解決

#### 問題
- 新しいルート：`/[lang]/[page]`（例：`/ja/Quartz`）
- 既存のルート：`/[page]`（例：`/Quartz`）
- Next.jsエラー：「異なるslug名を同じ動的パスで使えない」

#### 解決策
- 既存の`pages/[page].tsx`を`pages/nishio/[page].tsx`に移動
- Scrapboxビューアは`/nishio/<page>`でアクセス
- 新しいマークダウンビューアは`/[lang]/[page]`でアクセス
- プロジェクト名が"nishio"なので意味的にも適切

### 5. ビルドエラーの修正

#### エラー1：インポートパスの問題
- `components/RelatedPages.tsx`：`../pages/[page]` → `../pages/nishio/[page]`
- `pages/nishio/[page].tsx`：`../` → `../../`（ディレクトリ階層の変更）

#### エラー2：marked型エラー
- カスタムrendererのコードが新しいmarked APIと互換性なし
- 実際には使われていないコードだったため削除
- processWikiLinks関数のみで十分

### 6. Vercelデプロイの問題解決

#### 問題1：Node.jsバージョン
- 初期エラー：14.xは無効
- 修正1：18.x → エラー：discontinuedなので22.xが必要
- 最終修正：22.x → 成功

#### 問題2：データファイルの不在
ユーザーからの指摘：「Vercelでのビルドプロセスでコンテンツをcloneしてないから全部404になるんじゃない？」

**問題の原因**：
- Vercelは`mem`リポジトリのみをclone
- シンボリックリンク先（親リポジトリのサブモジュール）が存在しない

**解決策**：
`prebuild`スクリプトを追加：
```json
"prebuild": "bash -c 'if [ ! -d data/ja/pages ]; then rm -rf data/ja data/en && git clone --depth 1 https://github.com/nishio/external_brain_in_markdown data/ja && git clone --depth 1 https://github.com/nishio/external_brain_in_markdown_english data/en; fi'"
```

- Vercel環境：データリポジトリをclone
- ローカル環境：シンボリックリンクが存在するため何もしない
- `--depth 1`で高速clone

## コミット履歴

1. `ad6fc26` - Implement markdown viewer with language-specific routes
2. `bc41c89` - Fix build errors after file restructuring
3. `26701b9` - Specify Node.js 18.x for Vercel deployment
4. `7738250` - Upgrade to Node.js 22.x for Vercel deployment
5. `0e3f65d` - Add prebuild script to clone data repositories for Vercel

## 成果物

**実装されたルート**：
- `/ja/<page>` - 日本語マークダウン表示
- `/en/<page>` - 英語マークダウン表示
- `/nishio/<page>` - 既存のScrapboxビューア（従来通り）

**テストURL例**：
- http://localhost:3001/ja/Bashi
- http://localhost:3001/en/CLAUDE
- http://localhost:3001/ja/Quartz

## 学び

1. **ネストしたサブモジュールは避ける**：データの重複とメンテナンスの複雑化を招く
2. **シンボリックリンクはCI/CD環境で動作しない**：環境ごとに適切な対応が必要
3. **prebuildスクリプトで環境差を吸収**：ローカル/本番で異なるデータ配置方法を使える
4. **Next.jsの動的ルートは慎重に設計**：slug名の衝突に注意

## 今後の課題

- DeepL翻訳の品質が低い箇所を高品質な翻訳で上書きする仕組み（2023年の未完了タスク）
- GitHub Actionsによる自動更新（`docs/GITHUB_ACTIONS_PLAN.md`参照）
- ISR revalidation戦略の最適化

---

### 7. データパイプラインの調査

#### 調査目的
外部脳システムに以下の機能を追加するための現状調査：
1. タイムスタンプ付きメタデータJSON（各行の編集履歴）
2. 検索ツールの強化（更新日時、キーワード、ベクトル検索）
3. AI生成コンテンツの管理（人間由来データとの分離）

#### from_scrapboxの現状

**JSONデータの取得と保存**：
- `tasks/crawl_scrapbox/index.ts`がScrapbox APIからページデータを取得
- 一時的にJSON Lines形式（`.jsonl`）でデータを保存
- 最終的にMarkdownに変換後、生のJSONは削除される

**保存されているJSONファイル**：
- `page_title_map.json` (1MB): 日英タイトル対訳マップ
- `title_map.json` (2.1MB): タイトルマッピング
- `crawl_data/projects.json`: 監視対象のScrapboxプロジェクトリスト（1,319プロジェクト）

**取得データの構造**（crawl_scrapbox/index.ts参照）：
```typescript
interface TitlePage {
  id: string;
  title: string;
  created: number;    // タイムスタンプ
  updated: number;    // タイムスタンプ
  image: string;
  descriptions: string[];
}
```

→ **ページレベルのタイムスタンプは存在するが、行レベルのタイムスタンプは未実装**

#### etude-github-actionsの現状

**保存されているJSONファイル**：
- `cache.json` (95MB): DeepL翻訳結果のキャッシュ
- `data_en_diff.json` (4.8MB): 前回との差分データ
- `keywords.json` (652KB): キーワードリスト

**embedding関連の実装**：
- grep検索の結果、embedding/vectorに関連するコードは**見つからず**
- 現在は翻訳パイプラインのみで、ベクトル検索機能は未実装

#### 未実装の機能

以下の機能はすべて**未実装**：

1. **タイムスタンプ付きメタデータJSON**
   - 各行がいつ書かれたかの記録
   - 行レベルの編集履歴追跡

2. **検索ツールの強化**
   - 更新日時での絞り込み
   - キーワード検索（基本的なものはある）
   - ローカルで動作するベクトル検索

3. **AI生成コンテンツの管理**
   - 人間由来データとAI生成データの分離
   - 混在を防ぐフォルダー構造

#### 次のステップ候補

1. **from_scrapbox改造**: タイムスタンプ付きJSON永続化
2. **ベクトル検索パイプライン**: ローカルembedding生成（sentence-transformers等）
3. **検索CLIツール**: 更新日時・キーワード・ベクトル検索統合

**アーキテクチャの方向性**（ユーザーコメント）：
> 人間が使うUIとしてCosense(Scrapbox)は有能なのだが、「人間とAIが共同作業する」となったらGitHub上のMarkdownが有力になってくる。
> なのでCosense(Scrapbox)は「人間がデータを吐き出す場」であり、それをMarkdownにしてGitHubにいれてる`external_brain_in_markdown`が人間由来データのストレージ、AIが作成するものもGitHubに(混ざらないようにfolderわけするなどして)入れるのが良さそう
